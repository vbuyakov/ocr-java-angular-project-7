# Filebeat - collect logs from orion-microcrm-nginx
# Reads from shared volume nginx-logs (no /var/lib/docker/containers needed)
#
# Prerequisite: start orion-microcrm app first so the nginx-logs volume exists:
#   docker compose up -d
# Then start ELK:
#   docker compose -f docker-compose-elk.yml up -d

filebeat.inputs:
  - type: filestream
    id: orion-microcrm-nginx
    enabled: true
    paths:
      - /var/log/nginx/access_http.log
      - /var/log/nginx/error_http.log
    fields:
      log_source: nginx
      log_container: orion-microcrm-nginx
    fields_under_root: true

  - type: filestream
    id: orion-microcrm-back
    enabled: true
    paths:
      - /var/log/app/spring.log
    fields:
      log_source: back
      log_container: orion-microcrm-back
    fields_under_root: true

  - type: filestream
    id: orion-microcrm-front
    enabled: true
    paths:
      - /var/log/caddy/access.log
    fields:
      log_source: front
      log_container: orion-microcrm-front
    fields_under_root: true

# Required when using custom index name
setup.template.name: "ocr-ja7-logs"
setup.template.pattern: "ocr-ja7-logs-*"
setup.template.settings:
  index.number_of_replicas: 0
# Disable ILM (logstash_writer lacks cluster:admin/ilm/*)
setup.ilm.enabled: false

# Output: Elasticsearch directly
# Using elastic user: logstash_writer role keeps failing (403/drops). TODO: fix role
output.elasticsearch:
  hosts: ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
  username: "elastic"
  password: "${ELASTIC_PASSWORD}"
  index: "ocr-ja7-logs-%{+YYYY.MM.dd}"
  # Apply nginx ingest pipeline only for nginx inputs (log_source set via fields_under_root)
  pipelines:
    - pipeline: "nginx-access-log-parser"
      when.equals:
        log_source: "nginx"

output.logstash:
  enabled: false

logging.level: info
logging.to_files: false
